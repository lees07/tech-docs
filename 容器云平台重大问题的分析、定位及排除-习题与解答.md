### 1、下面哪个可以实现容器的调度与编排 （D）
A、Mesos
B、Docker Swarm
C、Kubernetes
D、以上都可以

**答案解析**：从 2014 年开始，容器领域就诞生了以 Mesos、Docker Swarm 及 Kubernetes 为代表的容器编排系统。在过去这几年间，容器编排技术已经呈现出“三国鼎立”之态势，各有个的用户群体，各有个的活动社区，但如今 Kubernetes 已经成为真正的领导者。

### 2、容器平台一般都包括 CI/CD、灰度发布、滚动升级、自动扩缩容、租户管理、安全认证等功能模块，下面哪个可以做为容器管理平台（D）
A、Rancher
B、Openshift
C、Kubesphere
D、以上都可以

**答案解析**：在容器编排技术之上，我们为了更好的让开发者使用这个编排系统，就有了容器平台的出现，典型开源代表有 Rancher、Openshift、Kubesphere 等，它们都包括 CI/CD、灰度发布、滚动升级、自动扩缩容、租户管理、安全认证等等功能模块。

### 3、当需要定位业务问题时，下面哪个说法正确 （D）
A、分析问题就是需要了解问题发生的时间点，问题发生时的上下文，环境场景等，并分析问题之间的关联关系
B、定位问题就是在分析问题后，我们可以接合各种日志、监控告警等平台提供的功能来排除干扰项，找到问题的诱发根因
C、复现问题就是需要按可能触发的因素去构建场景，尽量避开多个可能影响问题的因素混杂一起，去构造程序代码，来排除相互干扰而不利于复现问题
D、以上都正确

**答案解析**：D，都正确，是我们解决问题的三个基本要素。

### 4、运行在 Kubernetes 平台上的某个服务无法访问，最可能是哪个组件造成的？ （B）
A、kubelet
B、kube-proxy
C、kube-apiserver
D、kube-controller-manager

**答案解析**：B，kube-proxy 实现服务到容器的代理转发，它通过建立各种 iptables 规则，实现了服务路由。

### 5、Kubernetes 的 API Server 卡顿问题，最不可能是哪个原因造成的？ （C）
A、kube-apiserver 负载均衡策略失效
B、应用请求结果没有在 API Server 端做缓存，每次都直接查询 etcd
C、集群中有部分 Node 处于 NotReady 状态，与 API Server 失联
D、etcd 资源耗尽，负载过高，查询结果不能及时返回给 API Server

**答案解析**：C，因为所有的请求都假设发往一个固定的 API Server，导致该 API Server 节点负载较高，同时该 API Server 又会将查询请求固定的发给某个 etcd 节点，然而请求结果并没有在 API Server 端做缓存，每次都会直接查询 etcd，在从 etcd 中获取 Pod 信息又是从 default 子目录中全局搜索，每次请求都比较费时，这样导致某一个固定的 etcd 一直处理大量的费时的请求，最终将该 etcd 资源耗尽，负载过高，因而查询结果不能及时返回给 API Server，导致创建Pod时候拿不到相关的信息，Pod 创建工作无法进行，所以会使 API Server 卡顿。Node 处于 NotReady 状态，基本不会影响 API Server 卡顿。

### 6、Kubernetes 中的某个服务创建失败，一直处于 CrashLoopBackOff 中，最可能是哪个原因造成的？ （D）
A、没有可用的 Node 以供调度
B、开启了资源配额管理，但在当前调度的目标节点上资源不足
C、镜像下载失败
D、业务没有正常启动或者服务启动后运行失败，有非0的退出码

**答案解析**：D，从 Event 事件中获知 Pod 创建失败的原因可能有以下几种：没有可用的Node以供调度。开启了资源配额管理，但在当前调度的目标节点上资源不足。镜像下载失败，镜像下载失败通常为网络问题。但 CrashLoopBackOff 一般是业务没有正常启动引起，要么参数配置错误，要么环境变量设置不正常等。

### 7、Kubernetes 中，下面哪种情况可能不会导致 Node notReady？ （B）
A、kubelet 不正常工作
B、某个 kube-controller-manager 不正常
C、该节点上 calico/flannel 等网络插件异常
D、kube-proxy 不正常工作

**答案解析**：B，kube-controller-manager 只负责 controller 的管理与维护，不会涉及节点 notReady 情况发生，其他都和节点组件有关，所以是有可能的。

### 8、Kubernetes 中，如果某个服务在集群外部通过 NodePort 和 Ingress 访问都正常，但服务之间不正常，下面哪个最有可能引起？ （B）
A、服务 Pod 所在的 kubelet 调用容器网络接口失败
B、可能服务在不同的 namespace 中，并设置了不恰当的 networkpolicy
C、内部 dns 解析不正常
D、kube-proxy 生成了错误的 iptables 规则

**答案解析**：B，由于服务在集群外部通过 NodePort 和 Ingress 访问都正常，说明 Pod 所在节点的网络至少是正常的，svc 对应也正常（肯定生成了正确的 iptables)，dns 解析也正常，否则通过 Ingress 方式访问会失败。

### 9、Kubernetes 的某个服务容器突然重启了，最不可能是下面哪个条件造成的？ （B）
A、服务对应的 Pod 内存资源 limit 值达到了
B、服务对应的 Pod CPU 资源 limit 值达到了
C、服务所在的 Node 节点发现不满足服务的亲和或外亲和性条件
D、服务健康检查 livness probe 没有通过或依赖的服务发生了中断

**答案解析**：B，CPU是可压缩资源，一般不会引起服务的容器重启，其他情况皆会引起。

### 10、Kubernetes 的 Pod 无法执行 exec 和 logs，最不可能是下面哪个条件造成的？ （D）
A、kube-apiserver 在调用 Pod 所在的节点的 kubelet 时，10250 端口不通或者网络不通
B、Pod 正在 terminating 中
C、防火墙、iptables规则对 kubelet 端口数据包进行了拦截
D、服务所在的 Pod 中的业务 hang 住了，但 Pod 还在 running

**答案解析**：D，服务所在的 Pod 中的业务 hang 住了，但 Pod 还在 running，还是可以用 exec 进入容器，还是可以通过 logs 查看日志，只是此时没有日志输出，其他选项都可能引起。
